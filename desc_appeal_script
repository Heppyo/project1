import pandas as pd
import re
import csv
import time
import statistics
from typing import List, Dict
from openai import OpenAI

# Initialize OpenAI client
client = OpenAI(api_key='insert api_key')

def construct_prompt(job_listing: str) -> str:
    return f"""Analyser følgende jobbannonse og kategoriser språkbruken. Vær grundig og bruk HELE skalaen fra 0-10.

    VIKTIGE REGLER:
    1. Score (0-10) - BRUK HELE SKALAEN:
       - 0: Kun tekniske krav og fakta, helt uten markedsføring
       - 1-3: Hovedsakelig teknisk/faktabasert med minimal markedsføring
       - 4-7: Blanding av fakta og markedsføring
       - 8-9: Sterkt markedsførende språk
       - 10: Ekstrem grad av markedsføring, minimal faktainformasjon

    2. Ordtelling:
       - List opp ALLE deskriptive og appellerende ord
       - Deskriptive ord = konkrete jobbkrav, tekniske termer, kvalifikasjoner
       - Appellerende ord = markedsførende språk, positive adjektiver
       - Hvert ord skal listes opp, ikke bare antallet

    Jobbannonse:
    {job_listing}

    Gi svaret i følgende format:
    ANALYSE: [Detaljert analyse av språkbruken]
    SCORE: [0-10, bruk HELE skalaen]
    DESKRIPTIVE ORD: [Full liste over alle deskriptive/tekniske ord]
    APPELLERENDE ORD: [Full liste over alle appellerende/markedsførende ord]
    ORDTELLING:
    Deskriptive ord: [antall]
    Appellerende ord: [antall]"""

def query_openai(prompt: str) -> str:
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": """Du er en spesialisert AI-analytiker for jobbanalyse med følgende STRENGE regler:

                1. Konsistente kriterier for scoring:
                   - 0-3: Kun tekniske krav og faktiske arbeidsoppgaver
                   - 4-7: Blanding av fakta og markedsføring, men hovedsakelig faktabasert
                   - 8-10: Dominert av markedsføring og appellerende språk

                2. Ordtelling:
                   - Deskriptive ord: Konkrete jobbkrav, tekniske termer, arbeidstider, kvalifikasjoner
                   - Appellerende ord: Markedsførende språk, positive adjektiver, lovnader, kulturbeskrivelser

                3. Tellekriterier:
                   - Hvert ord telles KUN ÉN gang
                   - Sammensatte ord telles som ett ord
                   - Ignorer standardfraser som "vi tilbyr" og "vi søker"

                Du må være 100% konsistent i din analyse."""},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"An error occurred: {e}")
        return None

def extract_data(analysis):
    print(f"Raw analysis received: {analysis[:200]}...") # Debug line

    # Initialize the dictionary that will store all extracted data
    extracted_data = {}

    # Extract analysis text
    analysis_match = re.search(r'ANALYSE:\s*(.*?)(?=\nSCORE:|$)', analysis, re.IGNORECASE | re.DOTALL)
    analysis_text = analysis_match.group(1).strip() if analysis_match else "N/A"
    extracted_data['analysis'] = analysis_text

    # Extract score
    score_match = re.search(r'SCORE:\s*(\d+)', analysis, re.IGNORECASE)
    score = score_match.group(1) if score_match else "N/A"
    extracted_data['score'] = score

    # Extract descriptive words with validation
    desc_match = re.search(r'DESKRIPTIVE ORD:\s*(.*?)(?=\nAPPELLERENDE ORD:|$)', analysis, re.IGNORECASE | re.DOTALL)
    desc_words = desc_match.group(1).strip() if desc_match else "N/A"
    extracted_data['desc_words'] = desc_words

    # Validate descriptive words
    if desc_words.isdigit() or desc_words == "N/A":
        print("Warning: Descriptive words list contains only numbers or is empty")
        extracted_data['categorization_note'] = "Warning: Incomplete descriptive words list. "
    else:
        extracted_data['categorization_note'] = ""

    # Extract appeal words with validation
    appell_match = re.search(r'APPELLERENDE ORD:\s*(.*?)(?=\s*ORDTELLING|$)', analysis, re.IGNORECASE)
    appell_words = appell_match.group(1).strip() if appell_match else "N/A"
    extracted_data['appell_words'] = appell_words

    if appell_words.isdigit() or appell_words == "N/A":
        print("Warning: Appellerende words list contains only numbers or is empty")
        extracted_data['categorization_note'] += "Warning: Incomplete appellerende words list. "

    # Extract word counts
    desc_count_match = re.search(r'Deskriptive ord:\s*(\d+)', analysis, re.IGNORECASE)
    desc_count = desc_count_match.group(1) if desc_count_match else "0"
    extracted_data['descriptive_count'] = desc_count

    appeal_count_match = re.search(r'Appellerende ord:\s*(\d+)', analysis, re.IGNORECASE)
    appeal_count = appeal_count_match.group(1) if appeal_count_match else "0"
    extracted_data['appeal_count'] = appeal_count

    # Calculate confidence score based on response completeness
    confidence_parts = {
        'analysis': analysis_text != "N/A",
        'score': score != "N/A",
        'desc_words': desc_words != "N/A" and not desc_words.isdigit(),
        'appell_words': appell_words != "N/A" and not appell_words.isdigit(),
        'counts': desc_count != "0" and appeal_count != "0"
    }
    confidence_score = sum(confidence_parts.values()) / len(confidence_parts)
    extracted_data['confidence_score'] = str(round(confidence_score, 2))

    # Calculate word ratio
    try:
        total_words = int(desc_count) + int(appeal_count)
        word_ratio = round(int(appeal_count) / total_words, 2) if total_words > 0 else 0
    except:
        word_ratio = 0
    extracted_data['word_ratio'] = str(word_ratio)

    return extracted_data

    # Generate categorization note
    categorization_note = ""
    if int(desc_count) + int(appeal_count) < 5:
        categorization_note += "Low word count detected. "
    if confidence_score < 0.8:
        categorization_note += "Incomplete analysis detected. "
    if int(score) > 8 and int(appeal_count) < int(desc_count):
        categorization_note += "High score with low appeal word ratio. "
    if not categorization_note:
        categorization_note = "Analysis appears consistent"

    # Calculate word ratio
    try:
        total_words = int(desc_count) + int(appeal_count)
        word_ratio = round(int(appeal_count) / total_words, 2) if total_words > 0 else 0
    except:
        word_ratio = 0

    return {
        'analysis': analysis_text,
        'score': score,
        'desc_words': desc_words,
        'appell_words': appell_words,
        'descriptive_count': desc_count,
        'appeal_count': appeal_count,
        'confidence_score': str(round(confidence_score, 2)),
        'categorization_note': categorization_note,
        'word_ratio': str(word_ratio)
    }

def validate_analysis(extracted_data: Dict) -> Dict:
    try:
        score = int(extracted_data['score'])
        desc_count = int(extracted_data['descriptive_count'])
        app_count = int(extracted_data['appeal_count'])

        # Validate word counts
        if desc_count > 30 or app_count > 30:
            extracted_data['categorization_note'] += " Warning: Unusually high word count detected."

        # Calculate ratio-based score
        ratio = app_count / (desc_count + app_count) if (desc_count + app_count) > 0 else 0
        adj_score = round(ratio * 10)

        # Add adjusted score
        extracted_data['adj_score'] = str(adj_score)

        # Add score deviation note
        if abs(score - adj_score) > 3:
            extracted_data['categorization_note'] += f" Large score deviation ({score} vs {adj_score})."

        return extracted_data
    except Exception as e:
        print(f"Validation error: {e}")
        extracted_data['adj_score'] = 'N/A'
        return extracted_data

def count_words(text: str) -> int:
    # Remove HTML tags and count words
    clean_text = re.sub(r'<[^>]+>', '', text)
    words = re.findall(r'\w+', clean_text)
    return len(words)

def process_csv(file_path):
    results = []
    previous_scores = []

    try:
        df = pd.read_csv(file_path, nrows=50)
        print(f"Starting analysis of first 50 job listings...")

        for index, row in df.iterrows():
            print(f"\nProcessing listing {index + 1}/50")
            job_listing = row['text']

            # Skip empty listings or those with fewer than 50 words
            if pd.isna(job_listing) or str(job_listing).strip() == '':
                print(f"Skipping empty listing at index {index}")
                continue

            word_count = count_words(job_listing)
            if word_count < 50:
                print(f"Skipping listing at index {index} - only {word_count} words")
                continue

            prompt = construct_prompt(job_listing)
            response = query_openai(prompt)

            # Rest of the function remains the same...

            if response:
                extracted_data = extract_data(response)
                extracted_data = validate_analysis(extracted_data)

                # Keep the original text in job_listings
                extracted_data['job_listings'] = job_listing

                if previous_scores:
                    avg_score = sum(map(int, previous_scores)) / len(previous_scores)
                    current_score = int(extracted_data['score'])
                    if abs(current_score - avg_score) > 3:
                        second_response = query_openai(prompt)
                        second_data = extract_data(second_response)
                        second_data = validate_analysis(second_data)
                        second_data['job_listings'] = job_listing
                        if abs(int(second_data['score']) - avg_score) < abs(current_score - avg_score):
                            extracted_data = second_data

                previous_scores.append(extracted_data['score'])
                results.append(extracted_data)

            time.sleep(1)

        return results
    except Exception as e:
        print(f"Error processing CSV: {e}")
        return []

def analyze_consistency(results: List[Dict]) -> None:
    try:
        scores = [int(r['score']) for r in results]

        # Analyze score distribution
        score_distribution = {i: scores.count(i) for i in range(11)}
        print("\nScore Distribution:")
        for score, count in score_distribution.items():
            print(f"Score {score}: {count} listings")

        # Check for missing extreme scores
        if score_distribution[0] + score_distribution[1] + score_distribution[10] == 0:
            print("\nWarning: No extreme scores (0, 1, or 10) were assigned")

        # Rest of the analysis remains the same...

        print("\nConsistency Analysis:")
        print(f"Number of analyzed listings: {len(results)}")
        print(f"Score Range: {min(scores)}-{max(scores)}")
        print(f"Score Standard Deviation: {statistics.stdev(scores):.2f}")
        print(f"Average Score: {statistics.mean(scores):.2f}")
        print(f"Descriptive Words Range: {min(desc_counts)}-{max(desc_counts)}")
        print(f"Appellative Words Range: {min(app_counts)}-{max(app_counts)}")
        print(f"Average Descriptive Words: {statistics.mean(desc_counts):.2f}")
        print(f"Average Appellative Words: {statistics.mean(app_counts):.2f}")
    except Exception as e:
        print(f"Analysis error: {e}")

def run_analysis():
    file_path = "Article_1 listings2020.csv"  # Updated file name
    print("Starting analysis...")
    results = process_csv(file_path)

    if results:
        output_file = 'job_listing_analysis_results_2020.csv'  # Updated output name
        fieldnames = [
            'job_listings', 'analysis', 'score', 'desc_words', 'appell_words',
            'descriptive_count', 'appeal_count', 'confidence_score',
            'categorization_note', 'word_ratio', 'adj_score'
        ]

        with open(output_file, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            for result in results:
                writer.writerow(result)

        analyze_consistency(results)
        print(f"\nAnalysis complete. Results saved to {output_file}")
        return results
    else:
        print("No results to save")
        return None

# Run the analysis
results = run_analysis()
